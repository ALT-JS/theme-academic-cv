---
title: How GPT learn layer by layer
summary: This is a fundamental track project for COMPSCI194-196 LLM Agents and LLM Agents hackathon. We focused on exploring robust and generalizable internal representations of lightweight LLMs and investigating the progression of learned features with linear probes and sparse autoencoders in OthelloGPT. Our experiments reveal that SAEs provide a more robust and disentangled decoding of the features the model is learning, particularly for compositional attributes.
# tags:
#   - Deep Learning
date: '2025-01-01T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: 'https://arxiv.org/abs/2501.07108'

# image:
#   caption: Photo by rawpixel on Unsplash
#   focal_point: Smart

links:
  # - icon: twitter
  #   icon_pack: fab
  #   name: Follow
  #   url: https://twitter.com/georgecushen
url_code: 'https://github.com/ALT-JS/OthelloSAE'
url_pdf: 'https://arxiv.org/abs/2501.07108'
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---
